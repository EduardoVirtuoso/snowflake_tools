{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import ArrowResult. No Apache Arrow result set format can be used. ImportError: DLL load failed while importing arrow_iterator: Não foi possível encontrar o procedimento especificado.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "import os\n",
    "import holidays\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parametros de conexao\n",
    "PASSWORD = os.environ.get(\"senha_sf\")\n",
    "WAREHOUSE = \"EV\"\n",
    "ACCOUNT = \"ot57980.us-east-2.aws\"\n",
    "DATABASE = \"rede_vistorias\"\n",
    "SCHEMA = \"dbt_rvdata_marts\"\n",
    "USER=os.environ.get(\"usuario_sf\")\n",
    "\n",
    "connection_parameters = {\n",
    "   \"account\": ACCOUNT,\n",
    "   \"user\": USER,\n",
    "   \"password\": PASSWORD,\n",
    "   \"role\": \"ACCOUNTADMIN\",\n",
    "   \"warehouse\": WAREHOUSE,\n",
    "   \"database\": DATABASE,\n",
    "   \"schema\": SCHEMA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.6.1, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'numpy' in the local environment is 1.24.4, which does not fit the criteria for the requirement 'numpy'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'holidays' in the local environment is 0.22, which does not fit the criteria for the requirement 'holidays'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    }
   ],
   "source": [
    "#creating a snowflake session\n",
    "prod = Session.builder.configs(connection_parameters).create()\n",
    "prod.add_packages('snowflake-snowpark-python','pandas','numpy','scikit-learn','holidays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import IntegerType, StringType, StructType, StructField,TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "091003 (22000): Failure using stage area. Cause: [S3_CHURN GET and PUT commands are not supported with external stage]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 78\u001b[0m\n\u001b[0;32m     73\u001b[0m     df_snow\u001b[39m.\u001b[39mwrite\u001b[39m.\u001b[39mmode(\u001b[39m\"\u001b[39m\u001b[39moverwrite\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msave_as_table(\u001b[39m\"\u001b[39m\u001b[39mtempo_entrega\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moverwrite\u001b[39m\u001b[39m\"\u001b[39m, table_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mSUCCESS\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 78\u001b[0m my_copy_sp \u001b[39m=\u001b[39m prod\u001b[39m.\u001b[39;49msproc\u001b[39m.\u001b[39;49mregister(snowflake_function, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrede_vistorias.dbt_rvdata_marts.tempo_entrega_v1_old\u001b[39;49m\u001b[39m\"\u001b[39;49m, replace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     79\u001b[0m is_permanent\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, stage_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m@REDE_VISTORIAS.DBT_RVDATA.s3_churn\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\stored_procedure.py:523\u001b[0m, in \u001b[0;36mStoredProcedureRegistration.register\u001b[1;34m(self, func, return_type, input_types, name, is_permanent, stage_location, imports, packages, replace, if_not_exists, parallel, execute_as, strict, statement_params, source_code_display, **kwargs)\u001b[0m\n\u001b[0;32m    518\u001b[0m check_register_args(\n\u001b[0;32m    519\u001b[0m     TempObjectType\u001b[39m.\u001b[39mPROCEDURE, name, is_permanent, stage_location, parallel\n\u001b[0;32m    520\u001b[0m )\n\u001b[0;32m    522\u001b[0m \u001b[39m# register stored procedure\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_register_sp(\n\u001b[0;32m    524\u001b[0m     func,\n\u001b[0;32m    525\u001b[0m     return_type,\n\u001b[0;32m    526\u001b[0m     input_types,\n\u001b[0;32m    527\u001b[0m     name,\n\u001b[0;32m    528\u001b[0m     stage_location,\n\u001b[0;32m    529\u001b[0m     imports,\n\u001b[0;32m    530\u001b[0m     packages,\n\u001b[0;32m    531\u001b[0m     replace,\n\u001b[0;32m    532\u001b[0m     if_not_exists,\n\u001b[0;32m    533\u001b[0m     parallel,\n\u001b[0;32m    534\u001b[0m     strict,\n\u001b[0;32m    535\u001b[0m     statement_params\u001b[39m=\u001b[39;49mstatement_params,\n\u001b[0;32m    536\u001b[0m     execute_as\u001b[39m=\u001b[39;49mexecute_as,\n\u001b[0;32m    537\u001b[0m     api_call_source\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mStoredProcedureRegistration.register\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    538\u001b[0m     source_code_display\u001b[39m=\u001b[39;49msource_code_display,\n\u001b[0;32m    539\u001b[0m     anonymous\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39manonymous\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    540\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\stored_procedure.py:722\u001b[0m, in \u001b[0;36mStoredProcedureRegistration._do_register_sp\u001b[1;34m(self, func, return_type, input_types, sp_name, stage_location, imports, packages, replace, if_not_exists, parallel, strict, source_code_display, statement_params, execute_as, anonymous, api_call_source, skip_upload_on_content_match)\u001b[0m\n\u001b[0;32m    710\u001b[0m arg_names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39msession\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marg\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(input_types))]\n\u001b[0;32m    711\u001b[0m input_args \u001b[39m=\u001b[39m [\n\u001b[0;32m    712\u001b[0m     UDFColumn(dt, arg_name) \u001b[39mfor\u001b[39;00m dt, arg_name \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(input_types, arg_names[\u001b[39m1\u001b[39m:])\n\u001b[0;32m    713\u001b[0m ]\n\u001b[0;32m    715\u001b[0m (\n\u001b[0;32m    716\u001b[0m     handler,\n\u001b[0;32m    717\u001b[0m     code,\n\u001b[0;32m    718\u001b[0m     all_imports,\n\u001b[0;32m    719\u001b[0m     all_packages,\n\u001b[0;32m    720\u001b[0m     upload_file_stage_location,\n\u001b[0;32m    721\u001b[0m     custom_python_runtime_version_allowed,\n\u001b[1;32m--> 722\u001b[0m ) \u001b[39m=\u001b[39m resolve_imports_and_packages(\n\u001b[0;32m    723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session,\n\u001b[0;32m    724\u001b[0m     TempObjectType\u001b[39m.\u001b[39;49mPROCEDURE,\n\u001b[0;32m    725\u001b[0m     func,\n\u001b[0;32m    726\u001b[0m     arg_names,\n\u001b[0;32m    727\u001b[0m     udf_name,\n\u001b[0;32m    728\u001b[0m     stage_location,\n\u001b[0;32m    729\u001b[0m     imports,\n\u001b[0;32m    730\u001b[0m     packages,\n\u001b[0;32m    731\u001b[0m     parallel,\n\u001b[0;32m    732\u001b[0m     statement_params\u001b[39m=\u001b[39;49mstatement_params,\n\u001b[0;32m    733\u001b[0m     source_code_display\u001b[39m=\u001b[39;49msource_code_display,\n\u001b[0;32m    734\u001b[0m     skip_upload_on_content_match\u001b[39m=\u001b[39;49mskip_upload_on_content_match,\n\u001b[0;32m    735\u001b[0m )\n\u001b[0;32m    737\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m custom_python_runtime_version_allowed:\n\u001b[0;32m    738\u001b[0m     check_python_runtime_version(\n\u001b[0;32m    739\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39m_runtime_version_from_requirement\n\u001b[0;32m    740\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\udf_utils.py:880\u001b[0m, in \u001b[0;36mresolve_imports_and_packages\u001b[1;34m(session, object_type, func, arg_names, udf_name, stage_location, imports, packages, parallel, is_pandas_udf, is_dataframe_input, max_batch_size, statement_params, source_code_display, skip_upload_on_content_match)\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(\n\u001b[0;32m    877\u001b[0m         input_stream, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, compression\u001b[39m=\u001b[39mzipfile\u001b[39m.\u001b[39mZIP_DEFLATED\n\u001b[0;32m    878\u001b[0m     ) \u001b[39mas\u001b[39;00m zf:\n\u001b[0;32m    879\u001b[0m         zf\u001b[39m.\u001b[39mwritestr(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mudf_file_name_base\u001b[39m}\u001b[39;00m\u001b[39m.py\u001b[39m\u001b[39m\"\u001b[39m, code)\n\u001b[1;32m--> 880\u001b[0m     session\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mupload_stream(\n\u001b[0;32m    881\u001b[0m         input_stream\u001b[39m=\u001b[39;49minput_stream,\n\u001b[0;32m    882\u001b[0m         stage_location\u001b[39m=\u001b[39;49mupload_stage,\n\u001b[0;32m    883\u001b[0m         dest_filename\u001b[39m=\u001b[39;49mudf_file_name,\n\u001b[0;32m    884\u001b[0m         dest_prefix\u001b[39m=\u001b[39;49mdest_prefix,\n\u001b[0;32m    885\u001b[0m         parallel\u001b[39m=\u001b[39;49mparallel,\n\u001b[0;32m    886\u001b[0m         source_compression\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDEFLATE\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    887\u001b[0m         compress_data\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    888\u001b[0m         overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    889\u001b[0m         is_in_udf\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    890\u001b[0m         skip_upload_on_content_match\u001b[39m=\u001b[39;49mskip_upload_on_content_match,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    892\u001b[0m all_urls\u001b[39m.\u001b[39mappend(upload_file_stage_location)\n\u001b[0;32m    893\u001b[0m inline_code \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:113\u001b[0m, in \u001b[0;36mServerConnection._Decorator.log_msg_and_perf_telemetry.<locals>.log_and_telemetry.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m logger\u001b[39m.\u001b[39mdebug(msg)\n\u001b[0;32m    112\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m--> 113\u001b[0m result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    114\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m    115\u001b[0m duration \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:291\u001b[0m, in \u001b[0;36mServerConnection.upload_stream\u001b[1;34m(self, input_stream, stage_location, dest_filename, dest_prefix, parallel, compress_data, source_compression, overwrite, is_in_udf, skip_upload_on_content_match)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m             kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mfile_stream\u001b[39m\u001b[39m\"\u001b[39m: input_stream}\n\u001b[1;32m--> 291\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_query(\n\u001b[0;32m    292\u001b[0m             _build_put_statement(\n\u001b[0;32m    293\u001b[0m                 uri,\n\u001b[0;32m    294\u001b[0m                 stage_location,\n\u001b[0;32m    295\u001b[0m                 dest_prefix,\n\u001b[0;32m    296\u001b[0m                 parallel,\n\u001b[0;32m    297\u001b[0m                 compress_data,\n\u001b[0;32m    298\u001b[0m                 source_compression,\n\u001b[0;32m    299\u001b[0m                 overwrite,\n\u001b[0;32m    300\u001b[0m             ),\n\u001b[0;32m    301\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    302\u001b[0m         )\n\u001b[0;32m    303\u001b[0m \u001b[39m# If ValueError is raised and the stream is closed, we throw the error.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[39m# https://docs.python.org/3/library/io.html#io.IOBase.close\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:102\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m     99\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m    100\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m--> 102\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:96\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m ReauthenticationRequest \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m     98\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m     99\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m    100\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:366\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m         query_id_log \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m [queryID: \u001b[39m\u001b[39m{\u001b[39;00mex\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(ex, \u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to execute query\u001b[39m\u001b[39m{\u001b[39;00mquery_id_log\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mex\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 366\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n\u001b[0;32m    368\u001b[0m \u001b[39m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[39m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[39mif\u001b[39;00m block:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:347\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_statement_params\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m--> 347\u001b[0m     results_cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cursor\u001b[39m.\u001b[39;49mexecute(query, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    348\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify_query_listeners(\n\u001b[0;32m    349\u001b[0m         QueryRecord(results_cursor\u001b[39m.\u001b[39msfqid, results_cursor\u001b[39m.\u001b[39mquery)\n\u001b[0;32m    350\u001b[0m     )\n\u001b[0;32m    351\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecute query [queryID: \u001b[39m\u001b[39m{\u001b[39;00mresults_cursor\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\connector\\cursor.py:908\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[1;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements)\u001b[0m\n\u001b[0;32m    904\u001b[0m     is_integrity_error \u001b[39m=\u001b[39m (\n\u001b[0;32m    905\u001b[0m         code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m100072\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m     )  \u001b[39m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[0;32m    907\u001b[0m     error_class \u001b[39m=\u001b[39m IntegrityError \u001b[39mif\u001b[39;00m is_integrity_error \u001b[39melse\u001b[39;00m ProgrammingError\n\u001b[1;32m--> 908\u001b[0m     Error\u001b[39m.\u001b[39;49merrorhandler_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection, \u001b[39mself\u001b[39;49m, error_class, errvalue)\n\u001b[0;32m    909\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\connector\\errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrorhandler_wrapper\u001b[39m(\n\u001b[0;32m    269\u001b[0m     connection: SnowflakeConnection \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m    273\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m        exception to the first handler in that order.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m     handed_over \u001b[39m=\u001b[39m Error\u001b[39m.\u001b[39;49mhand_to_other_handler(\n\u001b[0;32m    291\u001b[0m         connection,\n\u001b[0;32m    292\u001b[0m         cursor,\n\u001b[0;32m    293\u001b[0m         error_class,\n\u001b[0;32m    294\u001b[0m         error_value,\n\u001b[0;32m    295\u001b[0m     )\n\u001b[0;32m    296\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handed_over:\n\u001b[0;32m    297\u001b[0m         \u001b[39mraise\u001b[39;00m Error\u001b[39m.\u001b[39merrorhandler_make_exception(\n\u001b[0;32m    298\u001b[0m             error_class,\n\u001b[0;32m    299\u001b[0m             error_value,\n\u001b[0;32m    300\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\connector\\errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m cursor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    344\u001b[0m     cursor\u001b[39m.\u001b[39mmessages\u001b[39m.\u001b[39mappend((error_class, error_value))\n\u001b[1;32m--> 345\u001b[0m     cursor\u001b[39m.\u001b[39;49merrorhandler(connection, cursor, error_class, error_value)\n\u001b[0;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[39melif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\connector\\errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    219\u001b[0m errno \u001b[39m=\u001b[39m error_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merrno\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m done_format_msg \u001b[39m=\u001b[39m error_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdone_format_msg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 221\u001b[0m \u001b[39mraise\u001b[39;00m error_class(\n\u001b[0;32m    222\u001b[0m     msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmsg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    223\u001b[0m     errno\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m errno \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mint\u001b[39m(errno),\n\u001b[0;32m    224\u001b[0m     sqlstate\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msqlstate\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    225\u001b[0m     sfqid\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    226\u001b[0m     query\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    227\u001b[0m     done_format_msg\u001b[39m=\u001b[39m(\n\u001b[0;32m    228\u001b[0m         \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m done_format_msg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mbool\u001b[39m(done_format_msg)\n\u001b[0;32m    229\u001b[0m     ),\n\u001b[0;32m    230\u001b[0m     connection\u001b[39m=\u001b[39mconnection,\n\u001b[0;32m    231\u001b[0m     cursor\u001b[39m=\u001b[39mcursor,\n\u001b[0;32m    232\u001b[0m )\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 091003 (22000): Failure using stage area. Cause: [S3_CHURN GET and PUT commands are not supported with external stage]"
     ]
    }
   ],
   "source": [
    "def snowflake_function(session: snowflake.snowpark.Session) -> str:\n",
    "\n",
    "    #puxar a data atual para delimitar o filtro de feriados\n",
    "    session.add_packages('snowflake-snowpark-python','pandas','numpy','holidays')\n",
    "\n",
    "    query_current_date = '''\n",
    "    select current_date() as current_date\n",
    "    '''\n",
    "    df = session.sql(query_current_date).to_pandas()\n",
    "\n",
    "    lista_feriados = []\n",
    "    feriados= holidays.Brazil()\n",
    "        \n",
    "    #colocando os feriados em uma lista    \n",
    "    for feriado in feriados['2018-01-01': df['CURRENT_DATE'][0].strftime(\"%m/%d/%Y\")] :\n",
    "        lista_feriados.append(feriado)\n",
    "\n",
    "    #query dados das vistorias\n",
    "    query = '''\n",
    "    select ID,CREATED_AT,FIRST_SENT_AT,\n",
    "    FRANCHISEE_ID,CLIENT_ID, TYPE, to_date(FIRST_SENT_AT) as date_only,\n",
    "    credits/100 as credits\n",
    "    from orders \n",
    "    where CANCELED_AT is null and FIRST_SENT_AT  > '2022-06-01' and (data['accompaniedInspection']['scheduleDate'] is null\n",
    "    OR data['details']['allowed_at_date'] is null)\n",
    "    ;\n",
    "    '''\n",
    "    df = session.sql(query).to_pandas()\n",
    "\n",
    "\n",
    "    def tempo_de_entrega(df):\n",
    "\n",
    "        horas_entrega = []\n",
    "        lista_atraso = []\n",
    "        for index,row in df.iterrows():\n",
    "            start = row['CREATED_AT'].date()\n",
    "            end = row['FIRST_SENT_AT'].date()\n",
    "            segundos = row['FIRST_SENT_AT'] -  row['CREATED_AT']\n",
    "            horas = segundos.total_seconds() / 60/60\n",
    "\n",
    "            # include holidays in a list\n",
    "            days = np.busday_count(start, end, holidays=lista_feriados)\n",
    "            tempo = round((days*24)+horas)\n",
    "            horas_entrega.append(tempo)\n",
    "\n",
    "            if row['CREATED_AT'].hour > 12:\n",
    "                if tempo > 72:\n",
    "                    lista_atraso.append('Atrasado')\n",
    "                else:\n",
    "                    lista_atraso.append('Em tempo')\n",
    "            else:\n",
    "                if tempo > 48:\n",
    "                    lista_atraso.append('Atrasado')\n",
    "                else:\n",
    "                    lista_atraso.append('Em tempo')   \n",
    "\n",
    "        df['atraso']=lista_atraso\n",
    "        df['horas_entrega']=horas_entrega\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df = tempo_de_entrega(df)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------\n",
    "    #salvando a tabela\n",
    "    df['CREATED_AT'] = df['CREATED_AT'].dt.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    df['FIRST_SENT_AT'] = df['FIRST_SENT_AT'].dt.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    lista_types = [StructField(\"ID\", StringType()),StructField(\"CREATED_AT\", TimestampType()),StructField(\"FIRST_SENT_AT\", TimestampType()),\n",
    "         StructField(\"FRANCHISEE_ID\", StringType()), StructField(\"CLIENT_ID\", StringType()),StructField(\"TYPE\", StringType()),\n",
    "         StructField(\"DATE_ONLY\", TimestampType()),StructField(\"CREDITS\", TimestampType())]\n",
    "    tschema = StructType(lista_types)\n",
    "    df_snow = session.create_dataframe(data = df,schema = tschema)\n",
    "    df_snow.write.mode(\"overwrite\").save_as_table(\"tempo_entrega\", mode=\"overwrite\", table_type=\"\")\n",
    "\n",
    "    return \"SUCCESS\"\n",
    "\n",
    "\n",
    "my_copy_sp = prod.sproc.register(snowflake_function, name=\"rede_vistorias.dbt_rvdata_marts.tempo_entrega_v1_old\", replace=True,\n",
    "is_permanent=True, stage_location=\"@REDE_VISTORIAS.DBT_RVDATA.s3_churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERSAO 2.0: CONTEMPLA A DATA DE LIBERAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "091003 (22000): Failure using stage area. Cause: [S3_CHURN GET and PUT commands are not supported with external stage]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 140\u001b[0m\n\u001b[0;32m    135\u001b[0m     df_snow\u001b[39m.\u001b[39mwrite\u001b[39m.\u001b[39mmode(\u001b[39m\"\u001b[39m\u001b[39moverwrite\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msave_as_table(\u001b[39m\"\u001b[39m\u001b[39mtempo_entrega_v2\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moverwrite\u001b[39m\u001b[39m\"\u001b[39m, table_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mSUCCESS\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 140\u001b[0m my_copy_sp \u001b[39m=\u001b[39m prod\u001b[39m.\u001b[39;49msproc\u001b[39m.\u001b[39;49mregister(snowflake_function, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrede_vistorias.dbt_rvdata_marts.tempo_entrega\u001b[39;49m\u001b[39m\"\u001b[39;49m, replace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    141\u001b[0m is_permanent\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, stage_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m@REDE_VISTORIAS.DBT_RVDATA.s3_churn\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\stored_procedure.py:523\u001b[0m, in \u001b[0;36mStoredProcedureRegistration.register\u001b[1;34m(self, func, return_type, input_types, name, is_permanent, stage_location, imports, packages, replace, if_not_exists, parallel, execute_as, strict, statement_params, source_code_display, **kwargs)\u001b[0m\n\u001b[0;32m    518\u001b[0m check_register_args(\n\u001b[0;32m    519\u001b[0m     TempObjectType\u001b[39m.\u001b[39mPROCEDURE, name, is_permanent, stage_location, parallel\n\u001b[0;32m    520\u001b[0m )\n\u001b[0;32m    522\u001b[0m \u001b[39m# register stored procedure\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_register_sp(\n\u001b[0;32m    524\u001b[0m     func,\n\u001b[0;32m    525\u001b[0m     return_type,\n\u001b[0;32m    526\u001b[0m     input_types,\n\u001b[0;32m    527\u001b[0m     name,\n\u001b[0;32m    528\u001b[0m     stage_location,\n\u001b[0;32m    529\u001b[0m     imports,\n\u001b[0;32m    530\u001b[0m     packages,\n\u001b[0;32m    531\u001b[0m     replace,\n\u001b[0;32m    532\u001b[0m     if_not_exists,\n\u001b[0;32m    533\u001b[0m     parallel,\n\u001b[0;32m    534\u001b[0m     strict,\n\u001b[0;32m    535\u001b[0m     statement_params\u001b[39m=\u001b[39;49mstatement_params,\n\u001b[0;32m    536\u001b[0m     execute_as\u001b[39m=\u001b[39;49mexecute_as,\n\u001b[0;32m    537\u001b[0m     api_call_source\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mStoredProcedureRegistration.register\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    538\u001b[0m     source_code_display\u001b[39m=\u001b[39;49msource_code_display,\n\u001b[0;32m    539\u001b[0m     anonymous\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39manonymous\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    540\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\stored_procedure.py:722\u001b[0m, in \u001b[0;36mStoredProcedureRegistration._do_register_sp\u001b[1;34m(self, func, return_type, input_types, sp_name, stage_location, imports, packages, replace, if_not_exists, parallel, strict, source_code_display, statement_params, execute_as, anonymous, api_call_source, skip_upload_on_content_match)\u001b[0m\n\u001b[0;32m    710\u001b[0m arg_names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39msession\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marg\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(input_types))]\n\u001b[0;32m    711\u001b[0m input_args \u001b[39m=\u001b[39m [\n\u001b[0;32m    712\u001b[0m     UDFColumn(dt, arg_name) \u001b[39mfor\u001b[39;00m dt, arg_name \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(input_types, arg_names[\u001b[39m1\u001b[39m:])\n\u001b[0;32m    713\u001b[0m ]\n\u001b[0;32m    715\u001b[0m (\n\u001b[0;32m    716\u001b[0m     handler,\n\u001b[0;32m    717\u001b[0m     code,\n\u001b[0;32m    718\u001b[0m     all_imports,\n\u001b[0;32m    719\u001b[0m     all_packages,\n\u001b[0;32m    720\u001b[0m     upload_file_stage_location,\n\u001b[0;32m    721\u001b[0m     custom_python_runtime_version_allowed,\n\u001b[1;32m--> 722\u001b[0m ) \u001b[39m=\u001b[39m resolve_imports_and_packages(\n\u001b[0;32m    723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session,\n\u001b[0;32m    724\u001b[0m     TempObjectType\u001b[39m.\u001b[39;49mPROCEDURE,\n\u001b[0;32m    725\u001b[0m     func,\n\u001b[0;32m    726\u001b[0m     arg_names,\n\u001b[0;32m    727\u001b[0m     udf_name,\n\u001b[0;32m    728\u001b[0m     stage_location,\n\u001b[0;32m    729\u001b[0m     imports,\n\u001b[0;32m    730\u001b[0m     packages,\n\u001b[0;32m    731\u001b[0m     parallel,\n\u001b[0;32m    732\u001b[0m     statement_params\u001b[39m=\u001b[39;49mstatement_params,\n\u001b[0;32m    733\u001b[0m     source_code_display\u001b[39m=\u001b[39;49msource_code_display,\n\u001b[0;32m    734\u001b[0m     skip_upload_on_content_match\u001b[39m=\u001b[39;49mskip_upload_on_content_match,\n\u001b[0;32m    735\u001b[0m )\n\u001b[0;32m    737\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m custom_python_runtime_version_allowed:\n\u001b[0;32m    738\u001b[0m     check_python_runtime_version(\n\u001b[0;32m    739\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39m_runtime_version_from_requirement\n\u001b[0;32m    740\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\udf_utils.py:880\u001b[0m, in \u001b[0;36mresolve_imports_and_packages\u001b[1;34m(session, object_type, func, arg_names, udf_name, stage_location, imports, packages, parallel, is_pandas_udf, is_dataframe_input, max_batch_size, statement_params, source_code_display, skip_upload_on_content_match)\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(\n\u001b[0;32m    877\u001b[0m         input_stream, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, compression\u001b[39m=\u001b[39mzipfile\u001b[39m.\u001b[39mZIP_DEFLATED\n\u001b[0;32m    878\u001b[0m     ) \u001b[39mas\u001b[39;00m zf:\n\u001b[0;32m    879\u001b[0m         zf\u001b[39m.\u001b[39mwritestr(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mudf_file_name_base\u001b[39m}\u001b[39;00m\u001b[39m.py\u001b[39m\u001b[39m\"\u001b[39m, code)\n\u001b[1;32m--> 880\u001b[0m     session\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mupload_stream(\n\u001b[0;32m    881\u001b[0m         input_stream\u001b[39m=\u001b[39;49minput_stream,\n\u001b[0;32m    882\u001b[0m         stage_location\u001b[39m=\u001b[39;49mupload_stage,\n\u001b[0;32m    883\u001b[0m         dest_filename\u001b[39m=\u001b[39;49mudf_file_name,\n\u001b[0;32m    884\u001b[0m         dest_prefix\u001b[39m=\u001b[39;49mdest_prefix,\n\u001b[0;32m    885\u001b[0m         parallel\u001b[39m=\u001b[39;49mparallel,\n\u001b[0;32m    886\u001b[0m         source_compression\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDEFLATE\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    887\u001b[0m         compress_data\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    888\u001b[0m         overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    889\u001b[0m         is_in_udf\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    890\u001b[0m         skip_upload_on_content_match\u001b[39m=\u001b[39;49mskip_upload_on_content_match,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    892\u001b[0m all_urls\u001b[39m.\u001b[39mappend(upload_file_stage_location)\n\u001b[0;32m    893\u001b[0m inline_code \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:113\u001b[0m, in \u001b[0;36mServerConnection._Decorator.log_msg_and_perf_telemetry.<locals>.log_and_telemetry.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m logger\u001b[39m.\u001b[39mdebug(msg)\n\u001b[0;32m    112\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m--> 113\u001b[0m result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    114\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m    115\u001b[0m duration \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:291\u001b[0m, in \u001b[0;36mServerConnection.upload_stream\u001b[1;34m(self, input_stream, stage_location, dest_filename, dest_prefix, parallel, compress_data, source_compression, overwrite, is_in_udf, skip_upload_on_content_match)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m             kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mfile_stream\u001b[39m\u001b[39m\"\u001b[39m: input_stream}\n\u001b[1;32m--> 291\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_query(\n\u001b[0;32m    292\u001b[0m             _build_put_statement(\n\u001b[0;32m    293\u001b[0m                 uri,\n\u001b[0;32m    294\u001b[0m                 stage_location,\n\u001b[0;32m    295\u001b[0m                 dest_prefix,\n\u001b[0;32m    296\u001b[0m                 parallel,\n\u001b[0;32m    297\u001b[0m                 compress_data,\n\u001b[0;32m    298\u001b[0m                 source_compression,\n\u001b[0;32m    299\u001b[0m                 overwrite,\n\u001b[0;32m    300\u001b[0m             ),\n\u001b[0;32m    301\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    302\u001b[0m         )\n\u001b[0;32m    303\u001b[0m \u001b[39m# If ValueError is raised and the stream is closed, we throw the error.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[39m# https://docs.python.org/3/library/io.html#io.IOBase.close\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:102\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m     99\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m    100\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m--> 102\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:96\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m ReauthenticationRequest \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m     98\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m     99\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m    100\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:366\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m         query_id_log \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m [queryID: \u001b[39m\u001b[39m{\u001b[39;00mex\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(ex, \u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to execute query\u001b[39m\u001b[39m{\u001b[39;00mquery_id_log\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mex\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 366\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n\u001b[0;32m    368\u001b[0m \u001b[39m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[39m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[39mif\u001b[39;00m block:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:347\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_statement_params\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m--> 347\u001b[0m     results_cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cursor\u001b[39m.\u001b[39;49mexecute(query, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    348\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify_query_listeners(\n\u001b[0;32m    349\u001b[0m         QueryRecord(results_cursor\u001b[39m.\u001b[39msfqid, results_cursor\u001b[39m.\u001b[39mquery)\n\u001b[0;32m    350\u001b[0m     )\n\u001b[0;32m    351\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecute query [queryID: \u001b[39m\u001b[39m{\u001b[39;00mresults_cursor\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\connector\\cursor.py:908\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[1;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements)\u001b[0m\n\u001b[0;32m    904\u001b[0m     is_integrity_error \u001b[39m=\u001b[39m (\n\u001b[0;32m    905\u001b[0m         code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m100072\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m     )  \u001b[39m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[0;32m    907\u001b[0m     error_class \u001b[39m=\u001b[39m IntegrityError \u001b[39mif\u001b[39;00m is_integrity_error \u001b[39melse\u001b[39;00m ProgrammingError\n\u001b[1;32m--> 908\u001b[0m     Error\u001b[39m.\u001b[39;49merrorhandler_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection, \u001b[39mself\u001b[39;49m, error_class, errvalue)\n\u001b[0;32m    909\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\connector\\errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrorhandler_wrapper\u001b[39m(\n\u001b[0;32m    269\u001b[0m     connection: SnowflakeConnection \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m    273\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m        exception to the first handler in that order.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m     handed_over \u001b[39m=\u001b[39m Error\u001b[39m.\u001b[39;49mhand_to_other_handler(\n\u001b[0;32m    291\u001b[0m         connection,\n\u001b[0;32m    292\u001b[0m         cursor,\n\u001b[0;32m    293\u001b[0m         error_class,\n\u001b[0;32m    294\u001b[0m         error_value,\n\u001b[0;32m    295\u001b[0m     )\n\u001b[0;32m    296\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handed_over:\n\u001b[0;32m    297\u001b[0m         \u001b[39mraise\u001b[39;00m Error\u001b[39m.\u001b[39merrorhandler_make_exception(\n\u001b[0;32m    298\u001b[0m             error_class,\n\u001b[0;32m    299\u001b[0m             error_value,\n\u001b[0;32m    300\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\connector\\errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m cursor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    344\u001b[0m     cursor\u001b[39m.\u001b[39mmessages\u001b[39m.\u001b[39mappend((error_class, error_value))\n\u001b[1;32m--> 345\u001b[0m     cursor\u001b[39m.\u001b[39;49merrorhandler(connection, cursor, error_class, error_value)\n\u001b[0;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[39melif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\.conda\\envs\\snowpark\\lib\\site-packages\\snowflake\\connector\\errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    219\u001b[0m errno \u001b[39m=\u001b[39m error_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merrno\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m done_format_msg \u001b[39m=\u001b[39m error_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdone_format_msg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 221\u001b[0m \u001b[39mraise\u001b[39;00m error_class(\n\u001b[0;32m    222\u001b[0m     msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmsg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    223\u001b[0m     errno\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m errno \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mint\u001b[39m(errno),\n\u001b[0;32m    224\u001b[0m     sqlstate\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msqlstate\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    225\u001b[0m     sfqid\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    226\u001b[0m     query\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    227\u001b[0m     done_format_msg\u001b[39m=\u001b[39m(\n\u001b[0;32m    228\u001b[0m         \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m done_format_msg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mbool\u001b[39m(done_format_msg)\n\u001b[0;32m    229\u001b[0m     ),\n\u001b[0;32m    230\u001b[0m     connection\u001b[39m=\u001b[39mconnection,\n\u001b[0;32m    231\u001b[0m     cursor\u001b[39m=\u001b[39mcursor,\n\u001b[0;32m    232\u001b[0m )\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 091003 (22000): Failure using stage area. Cause: [S3_CHURN GET and PUT commands are not supported with external stage]"
     ]
    }
   ],
   "source": [
    "def snowflake_function(session: snowflake.snowpark.Session) -> str:\n",
    "\n",
    "    #puxar a data atual para delimitar o filtro de feriados\n",
    "    session.add_packages('snowflake-snowpark-python','pandas','numpy','holidays')\n",
    "\n",
    "    query_current_date = '''\n",
    "    select current_date() as current_date\n",
    "    '''\n",
    "    df = session.sql(query_current_date).to_pandas()\n",
    "\n",
    "    lista_feriados = []\n",
    "    feriados= holidays.Brazil()\n",
    "        \n",
    "    #colocando os feriados em uma lista    \n",
    "    for feriado in feriados['2018-01-01': df['CURRENT_DATE'][0].strftime(\"%m/%d/%Y\")] :\n",
    "        lista_feriados.append(feriado)\n",
    "\n",
    "    #query dados das vistorias\n",
    "    query = '''\n",
    "    select ID,CREATED_AT,FIRST_SENT_AT,\n",
    "    FRANCHISEE_ID,CLIENT_ID, TYPE, to_date(FIRST_SENT_AT) as date_only,\n",
    "    credits/100 as credits,\n",
    "    regexp_replace(replace(data['accompaniedInspection']['scheduleDate'],' ','')::varchar(), '[A-Z]', '') as data_agendamento,\n",
    "    regexp_replace(replace(data['details']['allowed_at_date'],' ','')::varchar(), '[A-Z]', '') as data_liberacao\n",
    "    from orders \n",
    "    where CANCELED_AT is null and FIRST_SENT_AT  > '2022-06-01' order by created_at desc\n",
    "    ;\n",
    "    '''\n",
    "    df = session.sql(query).to_pandas()\n",
    "\n",
    "    def tratar_data(df,coluna_base):\n",
    "        lista_data = []\n",
    "\n",
    "        for x in df[coluna_base]:\n",
    "            try:\n",
    "                \n",
    "                lista_data.append(datetime.strptime(x, '%d/%m/%Y%H:%M'))\n",
    "            except:    \n",
    "                try:\n",
    "                    lista_data.append(datetime.strptime(x, '%d/%m/%y'))    \n",
    "                except:\n",
    "                    try:        \n",
    "                        lista_data.append(datetime.strptime(x, '%d/%m/%Y'))     \n",
    "                    except:\n",
    "                        lista_data.append(None)\n",
    "                        \n",
    "\n",
    "        return lista_data\n",
    "\n",
    "    #teste validade anos\n",
    "    lista_primeiro_ajuste = []\n",
    "    for x in df['DATA_LIBERACAO']:\n",
    "        try:\n",
    "            if x is not None and (int(x.split('/')[-1].split(':')[0][0:4]) > 2024 or int(x.split('/')[-1].split(':')[0][0:4]) < 2020) and len(x.split('/')[-1].split(':')[0]) > 2:\n",
    "                lista_primeiro_ajuste.append(None)\n",
    "            else:\n",
    "                lista_primeiro_ajuste.append(x)\n",
    "        except:\n",
    "            pass\n",
    "            lista_primeiro_ajuste.append(x)\n",
    "\n",
    "    df['DATA_LIBERACAO'] = lista_primeiro_ajuste\n",
    "\n",
    "    lista_primeiro_ajuste = []\n",
    "    for x in df['DATA_AGENDAMENTO']:\n",
    "        try:\n",
    "            if x is not None and (int(x.split('/')[-1].split(':')[0][0:4]) > 2024 or int(x.split('/')[-1].split(':')[0][0:4]) < 2020) and len(x.split('/')[-1].split(':')[0]) > 2:\n",
    "                lista_primeiro_ajuste.append(None)\n",
    "            else:\n",
    "                lista_primeiro_ajuste.append(x)\n",
    "        except:\n",
    "            pass\n",
    "            lista_primeiro_ajuste.append(x)\n",
    "\n",
    "    df['DATA_AGENDAMENTO'] = lista_primeiro_ajuste\n",
    "    \n",
    "    df['DATA_AGENDAMENTO_TRATADA'] = tratar_data(df,'DATA_AGENDAMENTO')\n",
    "    df['DATA_AGENDAMENTO_TRATADA'].fillna(df['CREATED_AT'],inplace = True)\n",
    "    df['DATA_LIBERACAO_TRATADA'] = tratar_data(df,'DATA_LIBERACAO')\n",
    "    df['DATA_LIBERACAO_TRATADA'].fillna(df['CREATED_AT'],inplace = True)\n",
    "\n",
    "    def tempo_de_entrega(df):\n",
    "\n",
    "        horas_entrega = []\n",
    "        lista_atraso = []\n",
    "        lista_used_date = []\n",
    "        for index,row in df.iterrows():\n",
    "            used_date = max(row['CREATED_AT'],row['DATA_LIBERACAO_TRATADA'],row['DATA_AGENDAMENTO_TRATADA'])\n",
    "            if used_date > row['FIRST_SENT_AT']:\n",
    "                used_date = row['CREATED_AT']\n",
    "            start = used_date.date()\n",
    "            end = row['FIRST_SENT_AT'].date()\n",
    "            segundos = row['FIRST_SENT_AT'] -  used_date\n",
    "            horas = segundos.total_seconds() / 60/60\n",
    "            lista_used_date.append(used_date)\n",
    "\n",
    "            # include holidays in a list\n",
    "            days = np.busday_count(start, end, holidays=lista_feriados)\n",
    "            total_dias = (end - start).days\n",
    "            tempo = round(horas-((total_dias - days)*24))\n",
    "            horas_entrega.append(tempo)\n",
    "\n",
    "            if row['CREATED_AT'].hour > 12:\n",
    "                if tempo > 72:\n",
    "                    lista_atraso.append('Atrasado')\n",
    "                else:\n",
    "                    lista_atraso.append('Em tempo')\n",
    "            else:\n",
    "                if tempo > 48:\n",
    "                    lista_atraso.append('Atrasado')\n",
    "                else:\n",
    "                    lista_atraso.append('Em tempo')   \n",
    "\n",
    "        df['atraso']=lista_atraso\n",
    "        df['horas_entrega']=horas_entrega\n",
    "        df['used_date'] = lista_used_date\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df = tempo_de_entrega(df)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------\n",
    "    #salvando a tabela\n",
    "    df['CREATED_AT'] = df['CREATED_AT'].dt.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    df['FIRST_SENT_AT'] = df['FIRST_SENT_AT'].dt.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    df['used_date'] = df['used_date'].dt.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    df['DATA_LIBERACAO_TRATADA']=df['DATA_LIBERACAO_TRATADA'].dt.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    df['DATA_AGENDAMENTO_TRATADA']=df['DATA_AGENDAMENTO_TRATADA'].dt.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    lista_types = [StructField(\"ID\", StringType()),StructField(\"CREATED_AT\", TimestampType()),StructField(\"FIRST_SENT_AT\", TimestampType()),\n",
    "         StructField(\"FRANCHISEE_ID\", StringType()), StructField(\"CLIENT_ID\", StringType()),StructField(\"TYPE\", StringType()),\n",
    "         StructField(\"DATE_ONLY\", TimestampType()),StructField(\"CREDITS\", StringType),\n",
    "         StructField(\"data_agendamento\", StringType()),StructField(\"data_liberacao\", StringType()),StructField(\"used_date\", StringType())]\n",
    "    tschema = StructType(lista_types)\n",
    "    df_snow = session.create_dataframe(data = df,schema = tschema)\n",
    "    df_snow.write.mode(\"overwrite\").save_as_table(\"tempo_entrega_v2\", mode=\"overwrite\", table_type=\"\")\n",
    "\n",
    "    return \"SUCCESS\"\n",
    "\n",
    "\n",
    "my_copy_sp = prod.sproc.register(snowflake_function, name=\"rede_vistorias.dbt_rvdata_marts.tempo_entrega\", replace=True,\n",
    "is_permanent=True, stage_location=\"@REDE_VISTORIAS.DBT_RVDATA.s3_churn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
